# convolution neural network

## 합성곱 신경망 \(convolution neural network: CNN\)

* CNN은 이미지 인식과 음성 인식 등 다양한 곳에서 사용되는데 ,  특히 이미지 인식 분야에서 딥러닝을 활용한 기겁은 거의다 CNN을 기초로 한다 

## 합성곱 계층 \(convolutional layer\) 과 풀링 계층\(pooling layer\)

* 지금까지 본 신경망은 인접하는 계층의 모든 뉴런과 결합되어 있고, 이를 완전연결 \(fully-connected, 전결합\)이라고 하며,  완전히 연결된 계층을 Affine 계층이라는 이름으로 구현하고 있다.
* 완전한 신경망은 Affine 계층 뒤에 활성화 함수인 ReLU계층 \(sigmoid계층\)이 이어진다 
* CNN 에서는 새로운 합성곱 계층과 풀링 계층이 추가된다. 즉, Affine = ReLU 연결이 Conv - ReLU - \(Pooling\)으로 바뀐다 
* 또한, CNN에서는 Affine-ReLU의 구성이 가능하며, 마지막 출력 계층에서는 Affine- Softmax를 그대로 사용할 수 있다 
* CNN에서는 패딩 padding, 스트라이드 stride  등 CNN 고유의 용어가 등장한다. 또, 각 계층 사이에는 3차원 데이터같이 입체적인 데이터가 흐른다는 점에서 완전연결 신경망과 다르다 

## 완전연결 계층의 문제점

* 바로, 데이터의 형상이 무시 된다는 사실이 문제점이다 
* 형상을 무시하고 모든 입력 데이터를 동등한 뉴런 \(같은 차원의 뉴런\)으로 취급하여 형상에 담긴 정보를 살릴 수 없다. 한편, 합성곱 계층은 형상을 유지한다 
* 이미지도 3차원 데이터로 입력 받음, 마찬가지로 다음계층에서도 3차원 데이터로 전달한다. 
* 그래서 CNN 에서는 이미지처럼 형상을 가진 데이터를 제대로 이해할 수 있다
* CNN에서는 합성곱 계층의 입출력 데이터를 특징맵 feature map 이라고 한다
* 입력 특징 맵을 input feature map, 출력 특징 맵을 output feature map이라고 한다 

## 합성곱 연산

* 합성곱 연산은 이미지 처리에서 말하는 필터 연산에 해당한다 
* 필터의 형상을 높이와 너비로 표기하며, 필터를 커널이라고 칭하기도 한다 
* 합성곱의 연산은 필터의 원도우 window를 일정한 간격으로 이동해가면 입력 데이터에 적용 
* 이를, 단일 곱셈 - 누산 \(fused multiply add : FMA\)이라 한다 
* 완전연결 신견망에는 가중치 매개변수와 편향이 존재하는데, CNN에서는 필터의 매개변수가 그동안의 가중치에 해당한다
* 그리고 CNN에서도 편향이 존재한다. 편향은 항상 하나\(1x1\)만 존재한다 

## 패딩 \(padding\)

* 합성곱 연산을 수행하지 전에 입력 데이터 주변을 특정 값\(예컨대 0\)으로 채움
* 패팅은 주로 출력 크기를 조정할 목적으로 사용한다 
* 즉, 합성곱 연산을 거칠 때마다 크기가 작아지면 어느 시점에서는 출력 크기가 1이 되어 버릴수 있다 
* 이러한 사태를 막기 위해서 패팅을 사용한다 

## 스트라이트 \(stride\)

* 필터를 적용하는 위치의 간격을 스트라이트라고 한다 
* 예를 들어 스트라이트를 2로 하면 필터를 적용하는 원도우가 두칸씩 이동

```text
입력 크기(H, W), 필터 크기(FH, FW), 출력 크기 (OH, OW), 패팅 P, 스트라이트 S
OH = ((H + P -FH)/S) + 1 (스트라이트 1로 설정)
OW = ((W + P -FW)/S) + 1 (스트라이트 1로 설정)
OH = ((H + 2P -FH)/S) + 1 (스트라이트 2로 설정)
OW = ((W + 2P -FW)/S) + 1 (스트라이트 2로 설정)
```

## 3차원 데이터의 합성곱 연산

* 이미지만 해도 세로, 가로에 더해서 채널까지 고려한 3차원 데이터이다 
* 2차원 일때와 비교하면, 길이 방향\(채널 방향\)으로 특징 맵이 늘어난다
* 채널 쪽으로 특징 맵이 여러 개 있다면 입력 데이터와 필터의 합성곱 연산을 채널마다 수행하고, 그 결과를 더해서 하나의 출력을 얻는다 
* 3차원의 합성곱 연산에서 주의할 점은 입력데이터의 채널수와 필터의 채널수가 같아야 한다 

## 블록으로 생각하기

* 3차원의 합성곱 연산은 데이터아 필터를 직육면체 블록이라고 생각하면 된다
* 입력데이터 \(C, H, W\) \* 필터 \(C, FH, FW\) = 출력데이터\(1, OH, OW\)
* 그럼 합성곱 연산의 출력으로 다수의 채널을 내보내려면 어떻게 해야 할까요? =&gt; 필터\(가중치\)를 다수 사용한다
* 입력데이터 \(C, H, W\) \* 필터 \(C, FH, FW, FN\) = 출력데이터\(FN, OH, OW\) 여기서 필터를 FN개 적용하면 출력 맵도 FN개 생성된다
* 합성곱 연산에도\(완전 연결 계층과 마찬가지로\) 편향이 쓰인다
* 입력데이터 \(C, H, W\) \* 필터 \(C, FH, FW, FN\) =&gt; 출력데이터\(FN, OH, OW\) + 편향 \(FN, 1, 1\) =&gt; \(FN, OH, OW\)
* 형상이 다른 블록의 덧셈은 넘파이의 브로드캐스트 기능으로 쉽게 구현이 가능하다 

## 배치 처리

* 신경처리에서는 입력 데이터를 한덩이로 묶어 배치를 처리했다 
* 완전 연결 신경망을 구현하면서는 이 방식을 지원하여 처리 효율을 높이고, 미니배치 방식의 학습도 지원하였다
* 합성곱 연산도 마찬가지로 배치 처리 를 지원하며, 각 계층을 흐르느 데이터의 차원을 하나 늘려 4차원 데이터로 저장 
* 입력데이터 \(N\(N개 데이터\) ,C, H, W\) \* 필터 \(C, FH, FW, FN\)
* =&gt; 출력데이터\(N\(N개 데이터\), FN, OH, OW\) + 편향 \(FN, 1, 1\)
* =&gt; \(N\(N개 데이터\), FN, OH, OW\)
* 이처럼 데이터는 4차원 형상을 가진 채 각 계층을 타고 흐릅니다 
* 여기에서 주의할 점으로는 신경망에 4차원 데이터가 하나 흐를 때마다 데이터 N개 대한 합성곱 연산이 이뤄진다는 것이다 
* 즉, N 회 분의 처리를 한 번에 수행하는 것이다

## 풀링 계층

* 풀링은 세로 가로 방향의 공간을 줄이는 연산이다 
* 최대 풀링은 대상 영역에서 최댓값을 취하는 연산인 반면,
* 평균 풀링은 대상 연역에서 평균을 계산한다 
* 이미지 인식 분야에서는 주로 최대 풀링을 사용한다. 

## 풀링 계층의 특징

1. 학습해야 할 매개 변수가 없다 
   * 풀링은 대상 영역에서 최댓값이나 평균을 취하는 명확한 처리이므로 특별히 학습할 것이 없다 
2. 채널 수가 변하지 않는다 
   * 풀링 연산은 입력 데이터의 채널 수 그대로 출력 데이터로 내보낸다, 채널 마다 독립적으로 계산하기 때문이다 
3. 입력의 변화에 영향을 적게 받는다 \(강건하다\)
   * 입력데이터가 조금 변해도 풀링의 결과는 잘 변하지 않는다. 

